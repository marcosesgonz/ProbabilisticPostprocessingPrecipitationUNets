{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook reproduces the training of the classical methods. The 'USE_FS_Columns' parameter inside the cells indicate whether the feature selection approach is used in the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "main_path = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(main_path)\n",
    "csvs_dir_ensemble = os.path.abspath(os.path.join('..','data','csvs_for_classic_methods'))\n",
    "\n",
    "from models.classic_models import *\n",
    "\n",
    "fs_columns = ['GFS_ysutr', 'ARPEGE_ysumc', 'GEM_uwtc', 'GEM_myjtr', 'GFS_uwmc', \n",
    "              'GFS_uwtr', 'ARPEGE_uwmc', 'ARPEGE_uwtc', 'GFS_uwtc', 'GEM_mynn2mc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climatological CSGD calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "list_station_names = set(name[:-len(name.split('_')[-1]) -1] for name in os.listdir('../data/csvs_for_classic_methods') if name.endswith('.csv'))\n",
    "len(list_station_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FS_Columns = True #It doesn't matter in climatological CSGD\n",
    "params_0_list = [(l,m,n,p) for l in [0.005,0.01,0.015,0.02] for m in [0.01,0.02,0.05,0.1] for n in np.arange(1,2,0.25) for p in [0.01,0.05,0.1,0.15]]\n",
    "\n",
    "total_n = 0\n",
    "total_crps = 0\n",
    "total_mae = 0\n",
    "total_bs = 0\n",
    "for station_name in list_station_names:\n",
    "    ensemb_train_file = os.path.join(csvs_dir_ensemble ,station_name + '_train.csv')\n",
    "    ensemb_test_file = os.path.join(csvs_dir_ensemble ,station_name + '_test.csv')\n",
    "    ensemb_train_df = pd.read_csv(ensemb_train_file).dropna()\n",
    "    ensemb_test_df = pd.read_csv(ensemb_test_file).dropna()\n",
    "    ground_truth_train = ensemb_train_df.iloc[:,1].values\n",
    "    ground_truth_test = ensemb_test_df.iloc[:,1].values\n",
    "    climat_csgd = CSGD(verbose=False)\n",
    "    params0 = climat_csgd.calc_initial_values(ground_truth = ground_truth_train, method='paper')\n",
    "    climat_csgd.fit_climatological(ground_truth = ground_truth_train, init_params = params0)#,params_0 = [0.01,0.02,1.5,0.1])\n",
    "    crps, mae, mse, bs = climat_csgd.predict(ground_truth_test, metric = 'all')\n",
    "    total_n += len(ground_truth_test)\n",
    "    total_crps += crps*len(ground_truth_test)\n",
    "    total_mae += mae*len(ground_truth_test)\n",
    "    total_bs += bs*len(ground_truth_test)\n",
    "    print(f'{station_name} MAE: {mae}')\n",
    "\n",
    "crps_value = total_crps/total_n\n",
    "mae_value = total_mae/total_n\n",
    "bs_value = total_bs/total_n\n",
    "print(total_n)\n",
    "print(f'Climatological. CRPS:{crps_value} MAE:{mae_value} BS:{bs_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive CSGD calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using SLSQP with constraints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FS_Columns = True \n",
    "\n",
    "params_0_list = [(l,m,n,p) for l in [0.005,0.01,0.015,0.02] for m in [0.01,0.02,0.05,0.1] for n in np.arange(1,2,0.25) for p in [0.01,0.05,0.1,0.15]]\n",
    "total_crps = 0\n",
    "total_mae = 0\n",
    "total_bs = 0\n",
    "total_n = 0\n",
    "estaciones_pesos = {}\n",
    "for i,station_name in enumerate(list_station_names):\n",
    "    print(f'·{i + 1}/{len(list_station_names)} {station_name}:')\n",
    "\n",
    "    ensemb_train_file = os.path.join(csvs_dir_ensemble ,station_name + '_train.csv')\n",
    "    ensemb_val_file = os.path.join(csvs_dir_ensemble ,station_name + '_val.csv')\n",
    "    ensemb_test_file = os.path.join(csvs_dir_ensemble ,station_name + '_test.csv')\n",
    "\n",
    "    ensemb_train_df = pd.read_csv(ensemb_train_file).dropna()\n",
    "    ensemb_val_df = pd.read_csv(ensemb_val_file).dropna()\n",
    "    ensemb_test_df = pd.read_csv(ensemb_test_file).dropna()\n",
    "\n",
    "    ground_truth_train = ensemb_train_df.iloc[:,1].values\n",
    "    ground_truth_val = ensemb_val_df.iloc[:,1].values\n",
    "    ground_truth_test = ensemb_test_df.iloc[:,1].values\n",
    "\n",
    "    if USE_FS_Columns:\n",
    "        wrf_ensemble_train = ensemb_train_df[fs_columns].values\n",
    "        wrf_ensemble_val = ensemb_val_df[fs_columns].values\n",
    "        wrf_ensemble_test = ensemb_test_df[fs_columns].values\n",
    "    else:\n",
    "        wrf_ensemble_train = ensemb_train_df.iloc[:,2:].values\n",
    "        wrf_ensemble_val = ensemb_val_df.iloc[:,2:].values\n",
    "        wrf_ensemble_test = ensemb_test_df.iloc[:,2:].values   \n",
    "    \n",
    "    n_station = len(ground_truth_test)\n",
    "    best_crps_val = 1\n",
    "    for params_0 in params_0_list:\n",
    "        pred_csgd = PredictiveCSGD(verbose=False)\n",
    "        pred_csgd.fit(ground_truth_train,wrf_ensemble_train, params_0 = params_0)#,params_0 = [0.01,0.02,1.5,0.1])\n",
    "        crps_val = pred_csgd.predict(ground_truth_val,wrf_ensemble_val)\n",
    "        if crps_val < best_crps_val:\n",
    "            best_crps_val = crps_val\n",
    "            best_pred_csgd = pred_csgd\n",
    "            best_init_params = params_0\n",
    "\n",
    "    crps_test, mae_test, mse_test, bs_test = best_pred_csgd.predict(ground_truth_test,wrf_ensemble_test, metrics = 'all')\n",
    "    print(f' Best params_init: {best_init_params}, best_params_fitted: {best_pred_csgd.fitted_params} \\n crps: {crps_test} mae: {mae_test} bs: {bs_test}')\n",
    "    total_n += n_station\n",
    "    total_crps += crps_test * n_station\n",
    "    total_mae += mae_test * n_station\n",
    "    total_bs += bs_test * n_station\n",
    "    estaciones_pesos[station_name] = {'pred':best_pred_csgd.fitted_params,'climat':best_pred_csgd.fitted_climat_params}\n",
    "\n",
    "crps_final = total_crps/total_n\n",
    "mae_final = total_mae / total_n\n",
    "bs_final = total_bs / total_n\n",
    "print(f' crps_final = {crps_final} mae = {mae_final} bs = {bs_final}')\n",
    "\n",
    "\"\"\"import pickle\n",
    "# Guardamos el diccionario en un archivo .pkl usando pickle\n",
    "with open('PredCSGD_pesos.pkl', 'wb') as f:\n",
    "    pickle.dump(estaciones_pesos, f)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analog Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FS_Columns = True\n",
    "total_n = 0\n",
    "total_crps = 0\n",
    "total_crps_ensemb = 0\n",
    "total_mae = 0\n",
    "total_mse = 0\n",
    "total_bs = 0\n",
    "for idx,station_name in enumerate(list_station_names):\n",
    "    print(f'·{idx}/{len(list_station_names)}.{station_name}:')\n",
    "    ensemb_train_file = os.path.join(csvs_dir_ensemble ,station_name + '_train.csv')\n",
    "    ensemb_val_file = os.path.join(csvs_dir_ensemble ,station_name + '_val.csv')\n",
    "    ensemb_test_file = os.path.join(csvs_dir_ensemble ,station_name + '_test.csv')\n",
    "    \n",
    "    ensemb_train_df = pd.read_csv(ensemb_train_file).dropna()\n",
    "    ensemb_val_df = pd.read_csv(ensemb_val_file).dropna()\n",
    "    ensemb_test_df = pd.read_csv(ensemb_test_file).dropna()\n",
    "    ground_truth_train = ensemb_train_df.iloc[:,1].values\n",
    "    ground_truth_test = ensemb_test_df.iloc[:,1].values\n",
    "\n",
    "    if USE_FS_Columns:\n",
    "        X_ensemb_train_df = ensemb_train_df.loc[:,fs_columns]\n",
    "        X_ensemb_val_df = ensemb_val_df.loc[:,fs_columns]\n",
    "        X_ensemb_test_df = ensemb_test_df.loc[:,fs_columns]\n",
    "    else:\n",
    "        X_ensemb_train_df = ensemb_train_df.iloc[:,2:]\n",
    "        X_ensemb_val_df = ensemb_val_df.iloc[:,2:]\n",
    "        X_ensemb_test_df = ensemb_test_df.iloc[:,2:]\n",
    "\n",
    "    AnEn = AnalogEnsemble(t_window=3)\n",
    "    AnEn.fit(X_train = X_ensemb_train_df, y_train = ensemb_train_df.iloc[:,1], X_val = X_ensemb_val_df, y_val = ensemb_val_df.iloc[:,1],\n",
    "              n_members_options=[25,35,50], masked_columns = fs_columns if USE_FS_Columns else None) \n",
    "    crps, mae, mse, bs = AnEn.predict(X_test = ensemb_test_df.iloc[:,2:], y_test = ensemb_test_df.iloc[:,1])\n",
    "    crps_ensemb = np.mean(crps_ensemble(ground_truth_test, X_ensemb_test_df.values))\n",
    "    total_n += len(ground_truth_test)\n",
    "    total_crps += crps*len(ground_truth_test)\n",
    "    total_crps_ensemb += crps_ensemb*len(ground_truth_test)\n",
    "    total_mae += mae*len(ground_truth_test)\n",
    "    total_mse += mse*len(ground_truth_test)\n",
    "    total_bs += bs*len(ground_truth_test)\n",
    "    print(f' CRPS: {crps} CRPS_ensemb: {crps_ensemb}')\n",
    "    print(f' BS {bs} MAE {mae} MSE {mse}')\n",
    "    print('')\n",
    "crps_value = total_crps/total_n\n",
    "mae_value = total_mae/total_n\n",
    "mse_value = total_mse/total_n\n",
    "bs_value = total_bs/total_n\n",
    "print(total_crps_ensemb/total_n)\n",
    "print(total_n)\n",
    "print(f'Climatological. CRPS:{crps_value} MAE:{mae_value} MSE:{mse_value} BS:{bs_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN-CSGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_FS_Columns = True\n",
    "total_crps = 0\n",
    "total_mae = 0\n",
    "total_bs = 0\n",
    "total_n = 0\n",
    "estaciones_pesos = {}\n",
    "for i,station_name in enumerate(list_station_names):\n",
    "    print(f'·{i + 1}/{len(list_station_names)} {station_name}:')\n",
    "\n",
    "    ensemb_train_file = os.path.join(csvs_dir_ensemble ,station_name + '_train.csv')\n",
    "    ensemb_val_file = os.path.join(csvs_dir_ensemble ,station_name + '_val.csv')\n",
    "    ensemb_test_file = os.path.join(csvs_dir_ensemble ,station_name + '_test.csv')\n",
    "\n",
    "    ensemb_train_df = pd.read_csv(ensemb_train_file).dropna()\n",
    "    ensemb_val_df = pd.read_csv(ensemb_val_file).dropna()\n",
    "    ensemb_test_df = pd.read_csv(ensemb_test_file).dropna()\n",
    "\n",
    "    ground_truth_train = ensemb_train_df.iloc[:,1].values\n",
    "    ground_truth_val = ensemb_val_df.iloc[:,1].values\n",
    "    ground_truth_test = ensemb_test_df.iloc[:,1].values\n",
    "    if USE_FS_Columns:\n",
    "        wrf_ensemble_train = ensemb_train_df[fs_columns].values\n",
    "        wrf_ensemble_val = ensemb_val_df[fs_columns].values\n",
    "        wrf_ensemble_test = ensemb_test_df[fs_columns].values\n",
    "    else:\n",
    "        wrf_ensemble_train = ensemb_train_df.iloc[:,2:].values\n",
    "        wrf_ensemble_val = ensemb_val_df.iloc[:,2:].values\n",
    "        wrf_ensemble_test = ensemb_test_df.iloc[:,2:].values\n",
    "    n_station = len(ground_truth_test)\n",
    "    best_crps_val = 1\n",
    "    anncsgd = ANNCSGD(verbose=False,learning_rate=1e-3, input_dim = wrf_ensemble_train.shape[1])\n",
    "    anncsgd.fit(wrf_ensemble_train,ground_truth_train,wrf_ensemble_val,ground_truth_val, seed = 11) \n",
    "    crps_test,mae_test, bs_test, var_bs_test = anncsgd.predict(wrf_ensemble_test,ground_truth_test)\n",
    "    crps_ensemb = np.mean(crps_ensemble(ground_truth_test, ensemb_test_df.iloc[:,2:].values))\n",
    "\n",
    "    print(f' crps: {crps_test} mae: {mae_test} bs: {bs_test} +- {np.sqrt(var_bs_test)}, crps_ensemble: {crps_ensemb}')\n",
    "    total_n += n_station\n",
    "    total_crps += crps_test * n_station\n",
    "    total_mae += mae_test * n_station\n",
    "    total_bs += bs_test * n_station\n",
    "    estaciones_pesos[station_name] = deepcopy(anncsgd.state_dict())\n",
    "\n",
    "torch.save(estaciones_pesos,'weights_10FS_anncsgd.pt')\n",
    "crps_final = total_crps/total_n\n",
    "mae_final = total_mae / total_n\n",
    "bs_final = total_bs / total_n\n",
    "print(f' crps_final = {crps_final} mae = {mae_final} bs = {bs_final}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
